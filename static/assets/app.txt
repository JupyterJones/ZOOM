from flask import Flask, render_template, request, jsonify, send_from_directory
import os
import cv2
import numpy as np
import moviepy.editor as mpy

app = Flask(__name__)
UPLOAD_FOLDER = 'static/upload/'
VIDEO_FOLDER = 'static/videos/'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(VIDEO_FOLDER, exist_ok=True)

# Route to serve uploaded images
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload():
    if 'image' not in request.files:
        return jsonify({'error': 'No file uploaded'})
    file = request.files['image']
    filepath = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(filepath)
    return jsonify({'filepath': filepath})

@app.route('/process', methods=['POST'])
def process():
    data = request.json
    image_path = data['image_path']
    points = data['points']
    zoom_level = float(data['zoom'])  # Convert zoom_level to float
    
    output_video = os.path.join(VIDEO_FOLDER, 'zoom_animation.mp4')
    create_zoom_video(image_path, points, zoom_level, output_video)
    return jsonify({'video_path': output_video})

# Function to create zoom effect

def create_zoom_video(image_path, points, zoom_level, output_video):
    img = cv2.imread(image_path)
    h, w, _ = img.shape
    frames = []
    num_frames = 60
    
    for i in range(num_frames):
        alpha = i / num_frames
        zoom_factor = 1 + alpha * zoom_level
        point = points[i % len(points)]
        cx, cy = int(point[0] * w), int(point[1] * h)
        
        # Define the cropping region
        x1 = max(cx - int(w / (2 * zoom_factor)), 0)
        y1 = max(cy - int(h / (2 * zoom_factor)), 0)
        x2 = min(cx + int(w / (2 * zoom_factor)), w)
        y2 = min(cy + int(h / (2 * zoom_factor)), h)
        cropped = img[y1:y2, x1:x2]
        resized = cv2.resize(cropped, (w, h))
        frames.append(resized)
    
    # Save as video
    video = mpy.ImageSequenceClip([cv2.cvtColor(f, cv2.COLOR_BGR2RGB) for f in frames], fps=30)
    video.write_videofile(output_video, codec='libx264')

@app.route('/video/<filename>')
def video(filename):
    return send_from_directory(VIDEO_FOLDER, filename)

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5100)
--------- index.html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Zoom & Video</title>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <style>
        img { max-width: 100%; cursor: crosshair; }
        #video-container { display: none; }
    </style>
</head>
<body>
    <h1>Upload an Image</h1>
    <input type="file" id="image-upload" accept="image/*">
    <br><br>
    <img id="uploaded-image" style="display:none;">
    <br>
    <label>Zoom Level: <input type="range" id="zoom-level" min="1" max="5" step="0.1" value="2"></label>
    <br>
    <button id="generate-video">Generate Zoom Video</button>
    <br><br>
    <div id="video-container">
        <h2>Generated Video</h2>
        <video id="zoom-video" controls></video>
    </div>
    
    <script>
        let imagePath = "";
        let points = [];

        $('#image-upload').on('change', function(event) {
            let file = event.target.files[0];
            let formData = new FormData();
            formData.append('image', file);
            
            $.ajax({
                url: '/upload',
                type: 'POST',
                data: formData,
                processData: false,
                contentType: false,
                success: function(response) {
                    imagePath = response.filepath;
                    $('#uploaded-image').attr('src', imagePath).show();
                    points = [];
                }
            });
        });

        $('#uploaded-image').on('click', function(event) {
            if (points.length < 3) {
                let imgOffset = $(this).offset();
                let x = (event.pageX - imgOffset.left) / $(this).width();
                let y = (event.pageY - imgOffset.top) / $(this).height();
                points.push([x, y]);
            }
        });

        $('#generate-video').on('click', function() {
            if (points.length < 3 || !imagePath) {
                alert('Please select three points on the image.');
                return;
            }
            
            let zoom = $('#zoom-level').val();
            
            $.ajax({
                url: '/process',
                type: 'POST',
                contentType: 'application/json',
                data: JSON.stringify({ image_path: imagePath, points: points, zoom: zoom }),
                success: function(response) {
                    $('#zoom-video').attr('src', response.video_path);
                    $('#video-container').show();
                }
            });
        });
    </script>
</body>
</html>
---------------------- i want to alter this to zooming in on only one point clicked
ChatGPT said:
ChatGPT

To modify your existing code to focus on zooming in on just one selected point (instead of three), you need to make a few key adjustments:

    Limit the number of points to 1: Since you want to focus on only one point, the frontend code should allow the user to select just one point.

    Change the backend to handle only one point: The backend code needs to be updated to process the zoom effect based on a single point instead of multiple points.

Here's how you can adjust your existing code:
1. Update the Frontend (index.html)

In the frontend code, change the logic to store only one point and send it to the server.

<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Zoom & Video</title>
    <script src="https://code.jquery.com/jquery-3.6.0.min.js"></script>
    <style>
        img { max-width: 100%; cursor: crosshair; }
        #video-container { display: none; }
    </style>
</head>
<body>
    <h1>Upload an Image</h1>
    <input type="file" id="image-upload" accept="image/*">
    <br><br>
    <img id="uploaded-image" style="display:none;">
    <br>
    <label>Zoom Level: <input type="range" id="zoom-level" min="1" max="5" step="0.1" value="2"></label>
    <br>
    <button id="generate-video">Generate Zoom Video</button>
    <br><br>
    <div id="video-container">
        <h2>Generated Video</h2>
        <video id="zoom-video" controls></video>
    </div>
    
    <script>
        let imagePath = "";
        let point = null;  // Store only one point

        $('#image-upload').on('change', function(event) {
            let file = event.target.files[0];
            let formData = new FormData();
            formData.append('image', file);
            
            $.ajax({
                url: '/upload',
                type: 'POST',
                data: formData,
                processData: false,
                contentType: false,
                success: function(response) {
                    imagePath = response.filepath;
                    $('#uploaded-image').attr('src', imagePath).show();
                    point = null;  // Reset point selection when a new image is uploaded
                }
            });
        });

        $('#uploaded-image').on('click', function(event) {
            if (!point) {  // Allow only one point selection
                let imgOffset = $(this).offset();
                let x = (event.pageX - imgOffset.left) / $(this).width();
                let y = (event.pageY - imgOffset.top) / $(this).height();
                point = [x, y];  // Store the selected point
            }
        });

        $('#generate-video').on('click', function() {
            if (!point || !imagePath) {
                alert('Please select a point on the image.');
                return;
            }
            
            let zoom = $('#zoom-level').val();
            
            $.ajax({
                url: '/process',
                type: 'POST',
                contentType: 'application/json',
                data: JSON.stringify({ image_path: imagePath, points: [point], zoom: zoom }),  // Send only one point
                success: function(response) {
                    $('#zoom-video').attr('src', response.video_path);
                    $('#video-container').show();
                }
            });
        });
    </script>
</body>
</html>

2. Update the Backend (app.py)

Now, you need to adjust the backend to handle the zoom effect on only one point instead of multiple points. Modify the create_zoom_video function to zoom in on just the first point in the list.

from flask import Flask, render_template, request, jsonify, send_from_directory
import os
import cv2
import numpy as np
import moviepy.editor as mpy

app = Flask(__name__)
UPLOAD_FOLDER = 'static/upload/'
VIDEO_FOLDER = 'static/videos/'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(VIDEO_FOLDER, exist_ok=True)

# Route to serve uploaded images
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload():
    if 'image' not in request.files:
        return jsonify({'error': 'No file uploaded'})
    file = request.files['image']
    filepath = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(filepath)
    return jsonify({'filepath': filepath})

@app.route('/process', methods=['POST'])
def process():
    data = request.json
    image_path = data['image_path']
    points = data['points']
    zoom_level = float(data['zoom'])  # Convert zoom_level to float
    
    output_video = os.path.join(VIDEO_FOLDER, 'zoom_animation.mp4')
    create_zoom_video(image_path, points, zoom_level, output_video)
    return jsonify({'video_path': output_video})

# Function to create zoom effect on a single point

def create_zoom_video(image_path, points, zoom_level, output_video):
    img = cv2.imread(image_path)
    h, w, _ = img.shape
    frames = []
    num_frames = 60
    
    # Only using the first point
    point = points[0]
    cx, cy = int(point[0] * w), int(point[1] * h)
    
    for i in range(num_frames):
        alpha = i / num_frames
        zoom_factor = 1 + alpha * zoom_level
        
        # Define the cropping region
        x1 = max(cx - int(w / (2 * zoom_factor)), 0)
        y1 = max(cy - int(h / (2 * zoom_factor)), 0)
        x2 = min(cx + int(w / (2 * zoom_factor)), w)
        y2 = min(cy + int(h / (2 * zoom_factor)), h)
        cropped = img[y1:y2, x1:x2]
        resized = cv2.resize(cropped, (w, h))
        frames.append(resized)
    
    # Save as video
    video = mpy.ImageSequenceClip([cv2.cvtColor(f, cv2.COLOR_BGR2RGB) for f in frames], fps=30)
    video.write_videofile(output_video, codec='libx264')

@app.route('/video/<filename>')
def video(filename):
    return send_from_directory(VIDEO_FOLDER, filename)

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5100)

Key Changes:

    Frontend: Changed the points array to store only one point.
    Backend: Adjusted the logic in create_zoom_video to use only the first point from the points list.

Now, users can select only one point on the image, and the zoom effect will focus on that single point. The rest of the logic remains the same for uploading the image, processing it, and generating the zoom video.
You said:
is there a way to slightly sharpen every few frames
ChatGPT said:
ChatGPT

Yes, you can apply sharpening to every few frames in your video. One way to do this is by using a kernel (a matrix) to sharpen the image in the create_zoom_video function. You can apply this sharpening effect periodically (e.g., every 5 frames) to add variation and improve the perceived sharpness during zooming.

Here’s how you can modify the backend to sharpen every few frames:
1. Define a Sharpening Kernel

A kernel is a matrix used to apply various effects like blurring, sharpening, etc. A simple sharpening kernel looks like this:

sharpening_kernel = np.array([[0, -1, 0],
                               [-1, 5,-1],
                               [0, -1, 0]])

This kernel will enhance the contrast between neighboring pixels and sharpen the image.
2. Apply Sharpening to Every Few Frames

You can apply this kernel to every few frames in the create_zoom_video function using cv2.filter2D(). Here's how you can modify the function to sharpen every 5th frame (you can adjust the interval as needed):
Updated create_zoom_video Function:

def create_zoom_video(image_path, points, zoom_level, output_video):
    img = cv2.imread(image_path)
    h, w, _ = img.shape
    frames = []
    num_frames = 60
    
    # Only using the first point
    point = points[0]
    cx, cy = int(point[0] * w), int(point[1] * h)
    
    # Define the sharpening kernel
    sharpening_kernel = np.array([[0, -1, 0],
                                  [-1, 5,-1],
                                  [0, -1, 0]])

    for i in range(num_frames):
        alpha = i / num_frames
        zoom_factor = 1 + alpha * zoom_level
        
        # Define the cropping region
        x1 = max(cx - int(w / (2 * zoom_factor)), 0)
        y1 = max(cy - int(h / (2 * zoom_factor)), 0)
        x2 = min(cx + int(w / (2 * zoom_factor)), w)
        y2 = min(cy + int(h / (2 * zoom_factor)), h)
        cropped = img[y1:y2, x1:x2]
        resized = cv2.resize(cropped, (w, h))
        
        # Apply sharpening to every 5th frame
        if i % 5 == 0:  # Sharpen every 5th frame (adjust as needed)
            resized = cv2.filter2D(resized, -1, sharpening_kernel)
        
        frames.append(resized)
    
    # Save as video
    video = mpy.ImageSequenceClip([cv2.cvtColor(f, cv2.COLOR_BGR2RGB) for f in frames], fps=30)
    video.write_videofile(output_video, codec='libx264')

Explanation of Changes:

    Sharpening Kernel: The sharpening kernel is defined as a 3x3 matrix that is applied to each frame to enhance its sharpness.
    Frame Interval: The condition if i % 5 == 0: ensures that the sharpening effect is applied to every 5th frame. You can adjust this number to apply sharpening more or less frequently.
    cv2.filter2D(): This function applies the kernel to the image, modifying the pixel values based on the kernel matrix. It sharpens the image by increasing the contrast around edges.

Optional: Customizing the Sharpening Interval

If you want to sharpen frames at different intervals, you can modify the condition in the loop. For example, you could sharpen frames every 3rd frame by changing i % 5 == 0 to i % 3 == 0.

With this setup, every few frames (e.g., every 5th frame), the image will be sharpened before it is added to the final video.
You said:
how can i slow down the zoom 
ChatGPT said:
ChatGPT

To slow down the zoom effect, you need to adjust the rate at which the zooming occurs in the video. Currently, the zooming effect is controlled by the alpha value, which increases linearly over the number of frames. By slowing down the zoom, you can decrease the rate at which alpha increases, resulting in a slower zoom effect.
Ways to Slow Down the Zoom:

    Reduce the Zoom Speed by Modifying alpha You can reduce the speed of the zoom by decreasing the increase rate of alpha. This will cause the zoom factor to change more slowly over time.

    Increase the Number of Frames for Smoother Zoom Increasing the number of frames can also make the zoom appear slower because there are more frames to interpolate the zoom effect.

Example Modifications to Slow Down the Zoom:
1. Slower Zoom by Reducing alpha Increment

In the current create_zoom_video function, the alpha is calculated as i / num_frames. You can introduce a "slow down factor" to reduce how quickly alpha increases.
Updated create_zoom_video with Slower Zoom:

def create_zoom_video(image_path, points, zoom_level, output_video, slowdown_factor=2):
    img = cv2.imread(image_path)
    h, w, _ = img.shape
    frames = []
    num_frames = 60 * slowdown_factor  # Increase the number of frames for slower zoom
    
    # Only using the first point
    point = points[0]
    cx, cy = int(point[0] * w), int(point[1] * h)
    
    # Define the sharpening kernel
    sharpening_kernel = np.array([[0, -1, 0],
                                  [-1, 5,-1],
                                  [0, -1, 0]])

    for i in range(num_frames):
        # Slow down the zoom by adjusting alpha
        alpha = (i / slowdown_factor) / num_frames  # Slow down the zoom by dividing alpha by slowdown_factor
        zoom_factor = 1 + alpha * zoom_level
        
        # Define the cropping region
        x1 = max(cx - int(w / (2 * zoom_factor)), 0)
        y1 = max(cy - int(h / (2 * zoom_factor)), 0)
        x2 = min(cx + int(w / (2 * zoom_factor)), w)
        y2 = min(cy + int(h / (2 * zoom_factor)), h)
        cropped = img[y1:y2, x1:x2]
        resized = cv2.resize(cropped, (w, h))
        
        # Apply sharpening to every 5th frame
        if i % 5 == 0:  # Sharpen every 5th frame (adjust as needed)
            resized = cv2.filter2D(resized, -1, sharpening_kernel)
        
        frames.append(resized)
    
    # Save as video
    video = mpy.ImageSequenceClip([cv2.cvtColor(f, cv2.COLOR_BGR2RGB) for f in frames], fps=30)
    video.write_videofile(output_video, codec='libx264')

Key Changes:

    Slow Down Factor:
        The slowdown_factor variable is added to control the zoom speed. The default value is set to 2, meaning the zoom effect will occur more slowly. You can adjust this factor to control how slow the zoom should be.
        The number of frames is also multiplied by the slowdown_factor, which increases the total number of frames for the zoom, making the effect slower.
        alpha is divided by the slowdown_factor to reduce the rate of zoom per frame.

    num_frames Adjustment:
        To make the zoom slower, the total number of frames (num_frames) is increased based on the slowdown_factor. This creates more intermediate frames, making the zoom appear slower.

2. More Gradual Zoom

If you want a more gradual zoom effect that starts slow and then speeds up a bit (or vice versa), you could use a non-linear curve for alpha instead of a linear one. A quadratic or cubic curve could make the zoom start slowly and then speed up, or the reverse.
Example of Quadratic Zoom (Starts Slow, Ends Fast):

alpha = (i / num_frames) ** 2  # This makes the zoom slower at the start and faster at the end

With these changes, the zoom will occur more slowly, and the effect can be adjusted by changing the slowdown_factor. You can experiment with different values for slowdown_factor and the alpha formula to get the exact zoom effect you want.
You said:
if i size the image for viewing on the page will it effect the point of zoom ?
ChatGPT said:
ChatGPT

Yes, resizing the image for viewing on the webpage can affect the point of zoom, especially if the image is scaled down for display. The coordinates where the user clicks to select the zoom points are based on the displayed size of the image, not the actual original size of the image.
Explanation:

    Image Display Size: When you display the image in HTML, you may scale it down using CSS (e.g., using max-width: 100% to fit the image to the screen). This makes the image smaller on the page for better viewing, but the actual dimensions of the image don't change. The image's width and height remain the same on the server side, while the displayed size on the page may be smaller.

    Zoom Coordinates: The user clicks on the displayed image, and those coordinates (in percentage terms) are calculated based on the scaled size of the image on the webpage, not the original image size. This mismatch can lead to an incorrect point of zoom when you use these coordinates to crop the image for zooming.

Solution: Adjust Coordinates Based on the Image Display Size

To fix this issue, you'll need to adjust the coordinates to account for the scaling when the image is displayed on the webpage. When the user clicks on the image, the click coordinates must be scaled back to the original image dimensions before applying the zoom effect.

Here’s how you can handle this:
1. Capture the Scaled Dimensions of the Image

When you load the image, capture both the displayed dimensions (the CSS size) and the original dimensions (the image file size).
2. Adjust Click Coordinates

When the user clicks on the image, convert the clicked position (relative to the displayed image) to the corresponding position in the original image based on the scaling factor.
Changes in Your Code:
Adjusting Click Coordinates in the Frontend (JavaScript)

$('#uploaded-image').on('click', function(event) {
    if (points.length < 3) {
        let imgOffset = $(this).offset();
        let imgWidth = $(this).width();
        let imgHeight = $(this).height();
        
        // Get the click coordinates relative to the displayed image
        let x = (event.pageX - imgOffset.left) / imgWidth;
        let y = (event.pageY - imgOffset.top) / imgHeight;
        
        // Store the coordinates relative to the original image dimensions
        points.push([x, y]);
    }
});

Adjusting Coordinates in the Backend (Python)

On the backend, when you perform the zoom, you should scale the coordinates back to the original image dimensions using the following formula:

# Convert the relative click coordinates to the original image's pixel coordinates
original_width = w  # Original image width
original_height = h  # Original image height

# Adjust the clicked point based on the original image dimensions
cx, cy = int(x * original_width), int(y * original_height)

Full Code Adjustments:

Here’s a step-by-step summary of the necessary changes:

    Frontend (HTML/JavaScript): When the user clicks on the image, calculate the coordinates as a percentage of the displayed image size (x and y values in terms of 0-1).

    Backend (Python): Convert these percentage-based coordinates back to the original image size before performing the zoom.

Why This Works:

    The click coordinates are always based on the visible image size (the CSS size), but the zoom effect is applied to the original image size. By scaling the click coordinates back to the original size, you ensure that the zoom happens at the correct location, even if the image is resized for display.

Let me know if you need any more details or adjustments to this solution!

----------------- current app.py -----------------
from flask import Flask, render_template, request, jsonify, send_from_directory
import os
import cv2
import numpy as np
import moviepy.editor as mpy
from moviepy.video.compositing.transitions import slide_in
from moviepy.video.fx import all
from moviepy.editor import *
import glob
import random
from PIL import Image
import cv2
import os
import uuid
import shutil
from sys import argv
app = Flask(__name__)
UPLOAD_FOLDER = 'static/upload/'
VIDEO_FOLDER = 'static/videos/'
os.makedirs(UPLOAD_FOLDER, exist_ok=True)
os.makedirs(VIDEO_FOLDER, exist_ok=True)
def add_title_image(video_path, hex_color = "#A52A2A"):
    hex_color=random.choice(["#A52A2A","#ad1f1f","#16765c","#7a4111","#9b1050","#8e215d","#2656ca"])
    # Define the directory path
    directory_path = "temp"
    # Check if the directory exists
    if not os.path.exists(directory_path):
        # If not, create it
        os.makedirs(directory_path)
        print(f"Directory '{directory_path}' created.")
    else:
        print(f"Directory '{directory_path}' already exists.") 
    # Load the video file and title image
    video_clip = VideoFileClip(video_path)
    print(video_clip.size)
    # how do i get the width and height of the video
    width, height = video_clip.size
    get_duration = video_clip.duration
    print(get_duration, width, height)
    title_image_path = "static/assets/port-hole.png"
    # Set the desired size of the padded video (e.g., video width + padding, video height + padding)
    padded_size = (width + 50, height + 50)

    # Calculate the position for centering the video within the larger frame
    x_position = (padded_size[0] - video_clip.size[0]) / 2
    y_position = (padded_size[1] - video_clip.size[1]) / 2
    #hex_color = "#09723c"
    # Remove the '#' and split the hex code into R, G, and B components
    r = int(hex_color[1:3], 16)
    g = int(hex_color[3:5], 16)
    b = int(hex_color[5:7], 16)

    # Create an RGB tuple
    rgb_tuple = (r, g, b)

    # Create a blue ColorClip as the background
    blue_background = ColorClip(padded_size, color=rgb_tuple)

    # Add the video clip on top of the red background
    padded_video_clip = CompositeVideoClip([blue_background, video_clip.set_position((x_position, y_position))])
    padded_video_clip = padded_video_clip.set_duration(video_clip.duration)
    #title_image_path = "/home/jack/Desktop/EXPER/static/assets/Title_Image02.png"
    # Load the title image
    title_image = ImageClip(title_image_path)

    # Set the duration of the title image
    title_duration = video_clip.duration
    title_image = title_image.set_duration(title_duration)

    print(video_clip.size)
    # Position the title image at the center and resize it to fit the video dimensions
    #title_image = title_image.set_position(("left", "top"))
    title_image = title_image.set_position((0, -5))
    #video_clip.size = (620,620)
    title_image = title_image.resize(padded_video_clip.size)

    # Position the title image at the center and resize it to fit the video dimensions
    #title_image = title_image.set_position(("center", "center")).resize(video_clip.size)

    # Create a composite video clip with the title image overlay
    composite_clip = CompositeVideoClip([padded_video_clip, title_image])
    # Limit the length to video duration
    composite_clip = composite_clip.set_duration(video_clip.duration)
    # Load a random background music
    mp3_files = glob.glob("static/music/*.mp3")
    random.shuffle(mp3_files)

    # Now choose a random MP3 file from the shuffled list
    mp_music = random.choice(mp3_files)
    get_duration = AudioFileClip(mp_music).duration
    # Load the background music without setting duration
    music_clip = AudioFileClip(mp_music)
    # Fade in and out the background music
    #music duration is same as video
    music_clip = music_clip.set_duration(video_clip.duration)
    # Fade in and out the background music
    fade_duration = 1.0
    music_clip = music_clip.audio_fadein(fade_duration).audio_fadeout(fade_duration)
    # Set the audio of the composite clip to the background music
    composite_clip = composite_clip.set_audio(music_clip)
    uid = uuid.uuid4().hex
    output_path = f'static/videos/final_output3{uid}.mp4'
    # Export the final video with the background music
    composite_clip.write_videofile(output_path)
    mp4_file =  f"/mnt/HDD500/collections/vids/Ready_Post_{uid}.mp4"
    shutil.copyfile(output_path, mp4_file) 
    temp_vid="static/videos/temp.mp4"
    shutil.copyfile(output_path, temp_vid)    
    print(mp4_file)
    VIDEO = output_path
    return VIDEO


# Route to serve uploaded images
@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload():
    if 'image' not in request.files:
        return jsonify({'error': 'No file uploaded'})
    file = request.files['image']
    filepath = os.path.join(UPLOAD_FOLDER, file.filename)
    file.save(filepath)
    return jsonify({'filepath': filepath})

@app.route('/process', methods=['POST'])
def process():
    data = request.json
    image_path = data['image_path']
    points = data['points']
    zoom_level = float(data['zoom'])  # Convert zoom_level to float
    
    output_video = os.path.join(VIDEO_FOLDER, 'zoom_animation.mp4')
    create_zoom_video(image_path, points, zoom_level, output_video)
    return jsonify({'video_path': output_video})

# Function to create zoom effect on a single point

def create_zoom_video(image_path, points, zoom_level, output_video):
    img = cv2.imread(image_path)
    h, w, _ = img.shape
    frames = []
    num_frames = 500
    
    # Only using the first point
    point = points[0]
    cx, cy = int(point[0] * w), int(point[1] * h)
    
    # Define the sharpening kernel
    sharpening_kernel = np.array([[0, -1, 0],
                                  [-1, 5,-1],
                                  [0, -1, 0]])

    for i in range(num_frames):
        #alpha = i / num_frames
        alpha = (i / num_frames) ** 2  # This makes the zoom slower at the start and faster at the end

        zoom_factor = 1 + alpha * zoom_level
        
        # Define the cropping region
        x1 = max(cx - int(w / (2 * zoom_factor)), 0)
        y1 = max(cy - int(h / (2 * zoom_factor)), 0)
        x2 = min(cx + int(w / (2 * zoom_factor)), w)
        y2 = min(cy + int(h / (2 * zoom_factor)), h)
        cropped = img[y1:y2, x1:x2]
        resized = cv2.resize(cropped, (w, h))
        
        # Apply sharpening to every 5th frame
        if i % 5 == 0:  # Sharpen every 5th frame (adjust as needed)
            resized = cv2.filter2D(resized, -1, sharpening_kernel)
        
        frames.append(resized)
    
    # Save as video
    video = mpy.ImageSequenceClip([cv2.cvtColor(f, cv2.COLOR_BGR2RGB) for f in frames], fps=30)
    video.write_videofile(output_video, codec='libx264')
    add_title_image(video_path=output_video)


@app.route('/video/<filename>')
def video(filename):
    return send_from_directory(VIDEO_FOLDER, filename)

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)
